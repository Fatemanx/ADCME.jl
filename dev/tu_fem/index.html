<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Numerical Scheme in ADCME: Finite Element Example · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../resources/">Video Lectures and Slides</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="../tu_optimization/">PDE Constrained Optimization</a></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li class="is-active"><a class="tocitem" href>Numerical Scheme in ADCME: Finite Element Example</a><ul class="internal"><li><a class="tocitem" href="#Why-do-you-need-while-loop?-1"><span>Why do you need while loop?</span></a></li><li><a class="tocitem" href="#D-Example-1"><span>1D Example</span></a></li><li><a class="tocitem" href="#D-Example-2"><span>2D Example</span></a></li><li><a class="tocitem" href="#Sensitivity-1"><span>Sensitivity</span></a></li><li><a class="tocitem" href="#Inversion-1"><span>Inversion</span></a></li><li><a class="tocitem" href="#Summary-1"><span>Summary</span></a></li></ul></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="../tu_recipe/">Inverse Modeling Recipe</a></li><li><a class="tocitem" href="../tu_nn/">Combining Neural Networks with Numerical Schemes</a></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li><li><a class="tocitem" href="../tu_customop/">Advanced: Custom Operators</a></li><li><a class="tocitem" href="../tu_debug/">Advanced: Debugging and Profiling</a></li><li><a class="tocitem" href="../exercise/">Exercise: Inverse Modeling with ADCME</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../optimizers/">Optimizers</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="../global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../nn/">Neural Networks</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li><li><a class="tocitem" href="../alphascheme/">Generalized α Scheme</a></li><li><a class="tocitem" href="../factorization/">Direct Methods for Sparse Matrices</a></li><li><a class="tocitem" href="../customopt/">Custom Optimizer</a></li><li><a class="tocitem" href="../options/">Global Options</a></li><li><a class="tocitem" href="../smt/">Managing Numerical Experiments with SMT</a></li></ul></li><li><span class="tocitem">Deep Learning Schemes</span><ul><li><a class="tocitem" href="../vae/">Variational Autoencoder</a></li><li><a class="tocitem" href="../flow/">Normalizing Flows</a></li><li><a class="tocitem" href="../convnet/">Convolutional Neural Network</a></li><li><a class="tocitem" href="../bnn/">Bayesian Neural Networks</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps/">Overview</a></li><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_adseismic/">General Seismic Inversion using Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_nnfem/">Symmetric Positive Definite Neural Networks (SPD-NN)</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorial</a></li><li class="is-active"><a href>Numerical Scheme in ADCME: Finite Element Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Numerical Scheme in ADCME: Finite Element Example</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/tu_fem.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Numerical-Scheme-in-ADCME:-Finite-Element-Example-1"><a class="docs-heading-anchor" href="#Numerical-Scheme-in-ADCME:-Finite-Element-Example-1">Numerical Scheme in ADCME: Finite Element Example</a><a class="docs-heading-anchor-permalink" href="#Numerical-Scheme-in-ADCME:-Finite-Element-Example-1" title="Permalink"></a></h1><p>The purpose of this tutorial is to show how to work with the finite element method (FEM) in ADCME. The tutorial is divided into two part. In the first part, we implement a finite element code for 1D Poisson equation using ADCME without custom operators. In the first part, you will understand how <a href="../api/#ADCME.while_loop-Tuple{Union{Function, PyCall.PyObject},Function,Union{PyCall.PyObject, Array{Any,N} where N, Array{PyCall.PyObject,N} where N}}"><code>while_loop</code></a> can help avoid creating a computational graph for each element. This is important because for many applications the number of elements in FEM can be enormous. The goal of the second part is to introduce <a href="../api/#ADCME.customop"><code>customop</code></a> for FEM. For performance critical applications, you may want to code your own loop over elements. However, in this case, you are responsible to calculate the sensititity of your finite element sensitivity matrix. </p><h2 id="Why-do-you-need-while-loop?-1"><a class="docs-heading-anchor" href="#Why-do-you-need-while-loop?-1">Why do you need while loop?</a><a class="docs-heading-anchor-permalink" href="#Why-do-you-need-while-loop?-1" title="Permalink"></a></h2><p>In engineering, we usually need to do for loops, e.g., time stepping, finite element matrix assembling, etc. In pseudocode, we have</p><pre><code class="language-julia">x = constant(0.0)
for i = 1:10000
  global x
	x = x + i 
end</code></pre><p>To do automatic differentiation in ADCME, direct implemnetation in the above way incurs creation of 10000 subgraphs, which requires large memories and long dependency parsing time. </p><p>Instead of relying on programming languages for the dynamic control flow, <code>TensorFlow</code> embeds control-flow as operations <em>inside</em> the dataflow graph. This is done via <code>while_loop</code>, which ADCME inherents from <code>TensorFlow</code>. <code>while_loop</code> allows for easier graph-based optimization, and reduces time and memory for the computational graph.</p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/while_loop_graph.png?raw=true" alt/></p><p>Using <code>while_loop</code>, the same function can be implemented as follows,</p><pre><code class="language-julia">function func(i, ta)
  xold = read(ta, i)
  x = xold + cast(Float64, i)
  ta = write(ta, i+1, x)
  return i+1, ta
end
i = constant(1, dtype = Int32)
ta = TensorArray(10001)
ta = write(ta, 1, constant(0.0))
_, out = while_loop((i, x)-&gt;i&lt;=10000, func, [i, ta])
result = stack(out)
sess = Session()
run(sess,result)</code></pre><p>Here <code>TensorArray(10001)</code> can be viewed as a container, which holds 10001 elements. These elements are tensors and can have sequential dependencies. One restriction on <code>TensorArray</code> is that all its elements must have the same type and size. This restriction requires us to &quot;initialize&quot; the <code>TensorArray</code> outside <code>while_loop</code>. The initialization is done by writting the first entry of <code>TensorArray</code> with a tensor (or a Julia numerical value/array), i.e., <code>ta=write(ta, 1, constant(0.0))</code>. A second important note is that if we want to have an loop index, <code>i</code>, the type of the loop index must be <code>Int32</code>. </p><p>The syntax for <code>while_loop</code> is </p><pre><code class="language-julia">i, ta1, ta2, ... = while_loop(condition, body, [i, ta1, ta2, ...])</code></pre><p>where <code>ta1</code>, <code>ta1</code>, ..., are different <code>TensorArrays</code>.</p><p>Inside a <code>body</code> function, we can use <code>read(ta, i)</code> to read the <code>i</code>-th value of the <code>TensorArray</code>. Note that the value must exist (written at an earlier time). After performing necessary computation, the result <code>v</code> is written the <code>i+1</code>-th index of <code>TensorArray</code> via <code>ta = write(ta, i+1, v)</code>. Note <code>write</code> is <strong>not</strong> an in-place function, so you need to update <code>ta</code> with its return value. Finally, the input and output of the <code>body</code> function must be consistent. </p><p>The <code>condition</code> function is a way to specify the stop criterion. It takes inputs <code>[i, ta1, ta2, ...]</code> and outputs a <strong>tensor boolean</strong>. For example, <code>i&lt;10000</code> is valid because <code>i</code> is a tensor, and <code>i&lt;10000</code> is interpreted as a tensor operation. </p><p>Finally, to convert <code>TensorArray</code> to normal tensors, we can use the function <code>stack</code>, which converts a <code>TensorArray</code> to a tensor. The first dimension of the converted tensor will be <code>?</code>. This is because without actually executing the computational graph, we never know the true size of <code>TensorArray</code>. For example, the stop criterio may be reached before the preassigned size. If you need to have a concrete shape of the tensor, you can use <a href="../api/#ADCME.set_shape-Union{Tuple{N}, Tuple{PyCall.PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s129,N} where N where #s129&lt;:Integer}}} where N"><code>set_shape</code></a> or <a href="../api/#Base.reshape-Union{Tuple{N}, Tuple{PyCall.PyObject,Union{Tuple{Vararg{Integer,N}}, Array{#s129,N} where N where #s129&lt;:Integer}}} where N"><code>reshape</code></a> to reshape the converted tensor. </p><h2 id="D-Example-1"><a class="docs-heading-anchor" href="#D-Example-1">1D Example</a><a class="docs-heading-anchor-permalink" href="#D-Example-1" title="Permalink"></a></h2><p>As a simple example, we consider assemble the external load vector for linear finite elements in 1D. Assume that the load distribution is <span>$f(x)=1-x^2$</span>, <span>$x\in[0,1]$</span>. The goal is to compute a vector <span>$\mathbf{v}$</span> with <span>$v_i=\int_{0}^1 f(x)\phi_i(x)dx$</span>, where <span>$\phi_i(x)$</span> is the <span>$i$</span>-th linear element. </p><p>The pseudocode for this problem is shown in the following</p><pre><code class="language-pseudocode">F = zeros(ne+1) // ne is the total number of elements
for e = 1:ne
  add load contribution to F[e] and F[e+1]
end</code></pre><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/externalforce.png?raw=true" alt/></p><p>However, if <code>ne</code> is very large, writing explicit loops is unwise since it will create <code>ne</code> subgraphs. <code>while_loop</code> can be very helpful in this case</p><pre><code class="language-julia">using ADCME

ne = 100
h = 1/ne
f = x-&gt;1-x^2
function cond0(i, F_arr)
    i&lt;=ne+1
end
function body(i, F_arr)
    fmid = f(cast(i-2, Float64)*h+h/2)
    F = vector([i-1;i], [fmid*h/2;fmid*h/2], ne+1)      # (1)
    F_arr = write(F_arr, i, F)
    i+1, F_arr
end

F_arr = TensorArray(ne+1)
F_arr = write(F_arr, 1, constant(zeros(ne+1))) # (2)
i = constant(2, dtype=Int32)
_, out = while_loop(cond0, body, [i,F_arr]; parallel_iterations=10)
F = sum(stack(out), dims=1)  # (3)
sess = Session(); init(sess)
F0 = run(sess, F)</code></pre><p>Detailed explaination: (1) <a href="../api/#ADCME.vector-Union{Tuple{T}, Tuple{Union{PyCall.PyObject, StepRange, UnitRange, Array{T,N} where N},Union{PyCall.PyObject, Array{Float64,N} where N},Union{Int64, PyCall.PyObject}}} where T&lt;:Integer"><code>vector(idx, val, len)</code></a> creates a length <code>len</code> vector with only the indices <code>idx</code> nonzero, populated with values <code>val</code>, i.e., <code>v[idx] = val</code>; (2) it is important to populate the first entry in a TensorArray, partially because of the need to inform <code>F_arr</code> of the data type; (3) <a href="../api/#ADCME.stack-Tuple{PyCall.PyObject}"><code>stack</code></a> extracts the output <code>out</code> as a tensor.  </p><h2 id="D-Example-2"><a class="docs-heading-anchor" href="#D-Example-2">2D Example</a><a class="docs-heading-anchor-permalink" href="#D-Example-2" title="Permalink"></a></h2><p>In this section, we demonstrate how to assemble a finite element matrix based on <code>while_loop</code> for a 2D Poisson problem. We consider the following problem</p><div>\[\begin{aligned}
\nabla \cdot ( D\nabla u(\mathbf{x}) ) &amp;= f(\mathbf{x})&amp; \mathbf{x}\in \Omega\\
u(\mathbf{x}) &amp;= 0 &amp; \mathbf{x}\in \partial \Omega
\end{aligned}\]</div><p>Here <span>$\Omega$</span> is the unit disk. We consider a simple case, where</p><div>\[\begin{aligned}
D&amp;=\mathbf{I}\\
f(\mathbf{x})&amp;=-4
\end{aligned}\]</div><p>Then the exact solution will be </p><div>\[u(\mathbf{x}) = 1-x^2-y^2\]</div><p>The weak formulation is</p><div>\[\langle \nabla v(\mathbf{x}), D\nabla u(\mathbf{x}) \rangle = \langle f(\mathbf{x}),v(\mathbf{x}) \rangle\]</div><p>We  split <span>$\Omega$</span> into triangles <span>$\mathcal{T}$</span> and use piecewise linear basis functions. Typically, we would iterate over all elements and compute the local stiffness matrix for each element. However, this could result in a large loop if we use a fine mesh. Instead, we can use <code>while_loop</code> to complete the task. </p><p>The implementation is split into two parts: </p><ul><li>The first part is associated with data preprocessing such as precompute finite element data. The quantities in this part do not require gradients and therefore can leverage the full performance of Julia. </li><li>The second part is accociated with finite element. Particularly, the quantity of interest is <span>$D$</span>, which we may want to estimate from data in the future. </li></ul><pre><code class="language-julia">using ADCME, LinearAlgebra, PyCall
using DelimitedFiles
using PyPlot

# read data 
elem = readdlm(&quot;meshdata/elem.txt&quot;, Int64)
node = readdlm(&quot;meshdata/nodes.txt&quot;)
dof = readdlm(&quot;meshdata/dof.txt&quot;, Int64)[:]
elem_ = constant(elem)
ne = size(elem,1)
nv = size(node, 1)

# precompute 
localcoef = zeros(ne, 3, 3)
areas = zeros(ne)
for e = 1:ne 
    el = elem[e,:]
    x1, y1 = node[el[1],:]
    x2, y2 = node[el[2],:]
    x3, y3 = node[el[3],:]
    A = [x1 y1 1.0; x2 y2 1.0; x3 y3 1.0]
    localcoef[e,:,:] = inv(A)
    areas[e] = 0.5*abs(det(A))
end

# compute right hand side using midpoint rule 
rhs = zeros(nv)
for i = 1:ne
    el = elem[i,:]
    rhs[el] .+= 4*areas[i]/3
end

areas = constant(areas)
localcoef = constant(localcoef)
D = constant(diagm(0=&gt;ones(2)))
function body(i, tai, taj, tav)
    el = elem_[i-1]
    a = areas[i-1]
    L = localcoef[i-1]
    LocalStiff = Array{PyObject}(undef, 3, 3)
    for i = 1:3
        for j = 1:3
            LocalStiff[i,j] = a*[L[1,i] L[2,i]]*D*[L[1,j];L[2,j]]|&gt;squeeze
        end
    end
    ii = reshape([el el el], (-1,))
    jj = reshape([el;el;el], (-1,))
    tai = write(tai, i, ii)
    taj = write(taj, i, jj)
    # op = tf.print(el)
    # i = bind(i, op)
    tav = write(tav, i, vcat(LocalStiff[:]...))
    return i+1, tai, taj, tav 
end

i = constant(2, dtype=Int32)
tai = TensorArray(ne+1, dtype=Int64)
taj = TensorArray(ne+1, dtype=Int64)
tav = TensorArray(ne+1)
tai = write(tai, 1, constant(ones(Int64,9)))
taj = write(taj, 1, constant(ones(Int64,9)))
tav = write(tav, 1, constant(zeros(9)))
_, ii, jj, vv = while_loop((i, tas...)-&gt;i&lt;=ne+1, body, [i, tai, taj, tav])
ii = reshape(stack(ii),(-1,)); jj = reshape(stack(jj),(-1,)); vv = reshape(stack(vv),(-1,))

A = SparseTensor(ii, jj, vv, nv, nv) # (1)

ndof = [x for x in setdiff(Set(1:nv), Set(dof))]
A = scatter_update(A, dof, ndof, spzero(length(dof), length(ndof)))  # (2)
A = scatter_update(A, ndof, dof, spzero(length(ndof), length(dof)))
A = scatter_update(A, dof, dof, spdiag(length(dof)))
rhs[dof] .= 0.0
sol = A\rhs  # (3)

sess = Session(); init(sess)
S = run(sess, sol)
close(&quot;all&quot;)
scatter3D(node[:,1], node[:,2], S, marker=&quot;^&quot;, label = &quot;FEM&quot;)
scatter3D(node[:,1], node[:,2], (@. 1-node[:,1]^2-node[:,2]^2), marker = &quot;+&quot;, label = &quot;Exact&quot;)
legend()</code></pre><p>The implementation in the <code>while_loop</code> part is a standard routine in FEM. Other detailed explaination: (1) We use <a href="../api/#ADCME.SparseTensor"><code>SparseTensor</code></a> to create a sparse matrix out of the row indices, column indices and values. (2) <a href="../api/#ADCME.scatter_update-Union{Tuple{T}, Tuple{S}, Tuple{Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}},Union{Colon, UnitRange{S}, Array{S,1}, Integer, PyCall.PyObject},Union{Colon, UnitRange{T}, Array{T,1}, Integer, PyCall.PyObject},Union{SparseTensor, SparseArrays.SparseMatrixCSC{Float64,Int64}}}} where T&lt;:Real where S&lt;:Real"><code>scatter_update</code></a> sets part of the sparse matrix to a given one. <a href="../api/#ADCME.spzero"><code>spzero</code></a> and <a href="../api/#ADCME.spdiag-Tuple{Int64}"><code>spdiag</code></a> are convenient ways to specify zero and identity sparse matrices. (3) The backslash operator will invoke a sparse solver (the default is SparseLU). </p><p><img src="https://github.com/ADCMEMarket/ADCMEImages/blob/master/ADCME/while_loop.png?raw=true" alt/></p><h2 id="Sensitivity-1"><a class="docs-heading-anchor" href="#Sensitivity-1">Sensitivity</a><a class="docs-heading-anchor-permalink" href="#Sensitivity-1" title="Permalink"></a></h2><p>The gradients with respect to the parameters in the finite element coefficient matrix, also known as the <strong>sensitivity</strong>, can be computed using automatic differentiation. For example, to extract the sensitivity of the solution norm with respect to D, we have </p><pre><code class="language-julia">gradients(sum(sol^2), D)</code></pre><p>The output is a 2 by 2 sensitivity matrix. </p><h2 id="Inversion-1"><a class="docs-heading-anchor" href="#Inversion-1">Inversion</a><a class="docs-heading-anchor-permalink" href="#Inversion-1" title="Permalink"></a></h2><p>If we only know the discrete solution, and the form of <span>$D=x\mathbf{I}$</span>, <span>$x&gt;0$</span>. This can be easily done by replacing <code>D = constant(diagm(0=&gt;ones(2)))</code> with (the initial guess for <span>$x=2$</span>)</p><pre><code class="language-julia">D = Variable(2.0) .* [1.0 0.0;0.0 1.0]</code></pre><p>Then, we can estimate <span>$x$</span> using L-BFGS-B </p><pre><code class="language-julia">loss = sum((sol - (@. 1-node[:,1]^2-node[:,2]^2))^2)
sess = Session(); init(sess)
BFGS!(sess, loss)</code></pre><p>The estimated result is </p><div>\[D = \begin{bmatrix}1.0028 &amp; 0.0\\ 0.0 &amp; 1.0028\end{bmatrix}\]</div><h2 id="Summary-1"><a class="docs-heading-anchor" href="#Summary-1">Summary</a><a class="docs-heading-anchor-permalink" href="#Summary-1" title="Permalink"></a></h2><p>Finite element analysis is a powerful tool in numerical PDEs. However, it is more conceptually sophisticated than the finite difference method and requires more implementation efforts. The important lesson we learned from this tutorial is the necessity of <code>while_loop</code>, how to separate the computation into pure Julia and ADCME C++ kernels, and how complex numerical schemes can be implemented in ADCME. </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tu_fd/">« Numerical Scheme in ADCME: Finite Difference Example</a><a class="docs-footer-nextpage" href="../tu_inv/">Inverse Modeling with ADCME »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 7 June 2020 21:57">Sunday 7 June 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
