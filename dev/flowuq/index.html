<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Uncertainty Quantification using Normalizing Flows · ADCME</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="ADCME logo"/></a><div class="docs-package-name"><span class="docs-autofit">ADCME</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><span class="tocitem">Tutorial</span><ul><li><a class="tocitem" href="../tutorial/">Overview</a></li><li><a class="tocitem" href="../tu_whatis/">What is ADCME? Computational Graph, Automatic Differentiation &amp; TensorFlow</a></li><li><a class="tocitem" href="../tu_basic/">ADCME Basics: Tensor, Type, Operator, Session &amp; Kernel</a></li><li><a class="tocitem" href="../tu_optimization/">PDE Constrained Optimization</a></li><li><a class="tocitem" href="../tu_sparse/">Sparse Linear Algebra</a></li><li><a class="tocitem" href="../tu_fd/">Numerical Scheme in ADCME: Finite Difference Example</a></li><li><a class="tocitem" href="../tu_fem/">Numerical Scheme in ADCME: Finite Element Example</a></li><li><a class="tocitem" href="../tu_inv/">Inverse Modeling with ADCME</a></li><li><a class="tocitem" href="../tu_recipe/">Inverse Modeling Recipe</a></li><li><a class="tocitem" href="../tu_nn/">Combining Neural Networks with Numerical Schemes</a></li><li><a class="tocitem" href="../tu_implicit/">Advanced: Automatic Differentiation for Implicit Operators</a></li><li><a class="tocitem" href="../tu_customop/">Advanced: Custom Operators</a></li><li><a class="tocitem" href="../tu_debug/">Advanced: Debugging</a></li><li><a class="tocitem" href="../exercise/">Exercise: Inverse Modeling with ADCME</a></li></ul></li><li><span class="tocitem">Resources</span><ul><li><a class="tocitem" href="../newton_raphson/">Newton Raphson</a></li><li><a class="tocitem" href="../parallel/">Parallel Computing</a></li><li><a class="tocitem" href="../ode/">PDE/ODE Solvers</a></li><li><a class="tocitem" href="../global/">Shared Memory Across Kernels</a></li><li><a class="tocitem" href="../julia_customop/">Julia Custom Operators</a></li><li><a class="tocitem" href="../nn/">Neural Networks</a></li><li><a class="tocitem" href="../ot/">Optimal Transport</a></li><li><a class="tocitem" href="../resource_manager/">Resource Manager</a></li><li><a class="tocitem" href="../alphascheme/">Generalized α Scheme</a></li><li><a class="tocitem" href="../factorization/">Direct Methods for Sparse Matrices</a></li><li><a class="tocitem" href="../customopt/">Custom Optimizer</a></li><li><a class="tocitem" href="../options/">Global Options</a></li></ul></li><li><span class="tocitem">Applications</span><ul><li><a class="tocitem" href="../apps/">Overview</a></li><li><a class="tocitem" href="../apps_ana/">Adversarial Numerical Analysis</a></li><li><a class="tocitem" href="../apps_levy/">Calibrating Multivariate Lévy Processes with Neural Networks</a></li><li><a class="tocitem" href="../apps_constitutive_law/">Learning Constitutive Relations from Indirect Observations Using Deep Neural Networks</a></li><li><a class="tocitem" href="../apps_ad/">Intelligent Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_adseismic/">General Seismic Inversion using Automatic Differentiation</a></li><li><a class="tocitem" href="../apps_nnfem/">Symmetric Positive Definite Neural Networks (SPD-NN)</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Uncertainty Quantification using Normalizing Flows</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Uncertainty Quantification using Normalizing Flows</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kailaix/ADCME.jl/blob/master/docs/src/flowuq.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Uncertainty-Quantification-using-Normalizing-Flows-1"><a class="docs-heading-anchor" href="#Uncertainty-Quantification-using-Normalizing-Flows-1">Uncertainty Quantification using Normalizing Flows</a><a class="docs-heading-anchor-permalink" href="#Uncertainty-Quantification-using-Normalizing-Flows-1" title="Permalink"></a></h1><p>The forward problem represents a mapping from model parameters to observations. The mapping might result from a discretized system of partial differentiatial equations. The model is written as </p><div>\[F(u, \theta) = 0\]</div><p>where <span>$u\in \mathbb{R}^N$</span> is the discrete state vector of <span>$N$</span> unknowns, and <span>$\theta\in \mathbb{R}^p$</span>  is the physical parameter from a domain <span>$D\subset \mathbb{R}^p$</span>. </p><p>The observation is typically a linear combination of state vectors</p><div>\[y = Cu\]</div><p>where <span>$y\in\mathbb{R}^q$</span> is a vector of <span>$q$</span> output and <span>$C\in \mathbb{R}^{q\times N}$</span> is a constant matrix.</p><p>The <strong>forward problem</strong> can be stated as: given a model parameter <span>$\theta$</span>, calculate <span>$y$</span>. In a data-driven model, we have measurement of the output, <span>$\tilde y$</span>, and we want to estimate the model parameter <span>$\theta$</span> from this measurement. This procedure is called the <strong>inverse problem</strong>.</p><p>The deterministic inverse problem seeks the optimal model parameter <span>$\theta$</span>, which solves  <span>$\begin{aligned} \min_{\theta, \theta}&amp;\; \|y - \tilde y\|_2^2\\
\text{s.t.}&amp;\; F(u, \theta) = 0\\  &amp;\; y = Cu \end{aligned}\tag{1}$</span> However, solving the deterministic inverse problem only gives us an estimate of the model parameter <span>$\theta$</span> without any information on the uncertainty of our estimation. To quantify the uncertainty, we can recast the inverse problem in the Bayesian framework, where we seek the <strong>posterior probability</strong>, <span>$p(\theta|\tilde y)$</span>, of the model parameter.</p><p>We consider the case where we have some measurement errors in the outputs <span>$y = Cu + \epsilon$</span> where <span>$\epsilon$</span> is a zero-mean Gaussian random variable, and its errors in each component are uncorrelated and have the same standard deviation <span>$\sigma$</span>. In the Bayesian framework, we also assign a <strong>prior distribution</strong> <span>$p(\theta)$</span> to the model parameter. </p><p>Before we describe our method, let us see how this stochastic inverse problem is solved using the standard approach. In the MCMC approach, we apply the Bayes formula and obtain </p><div>\[p(\theta|\tilde y) = \frac{p(\tilde y | \theta) p(\theta)}{p(\tilde y)}\]</div><p>We assume a non-informative prior, i.e., <span>$p(\theta)\propto 1$</span>, and therefore</p><div>\[p(\theta|\tilde y) \propto \exp\left[ -\frac{1}{2\sigma^2} (\tilde y-y(\theta))^T(\tilde y-y(\theta)) \right]\tag{2}\]</div><p>where <span>$y(\theta)$</span> is the solution to the system Equation (1) for a given parameter <span>$\theta$</span>. The Metropolis-Hastings MCMC algorithm is then used to numerically sample from the posterior distribution in Equation (2). However, the MCMC approach suffers from two critical issues that make them less challenging in practice:</p><ol><li>The forward computation of <span>$y(\theta)$</span> at every sampling step can be very expensive for large-scale scientific computing problems. </li><li>The MCMC approach is only able to synthesize samples from a data distribution <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup>, making the approach incapable of statistical inference tasks that requires explicit likelihood functions. </li></ol><p>We address this issue by modeling the posterior distribution <span>$p(\tilde y|\theta)$</span> directly using normalizing flows. This approach models the likelihood function directly and enables cheap sampling. </p><p>First, instead of modeling <span>$\theta$</span> directly, we consider transforming latent variables <span>$z$</span> to <span>$\theta$</span> using deep latent Gaussian models, where latent variables <span>$z_1$</span>, <span>$z_2$</span>, <span>$\ldots$</span>, <span>$z_L$</span>, <span>$z_{L+1} = z$</span>, and <span>$\theta$</span> have a joint distribution</p><div>\[p(\theta, z_1, z_2, \ldots, z_L| z_{L+1})  = p(\theta|f_0(z_1))\Pi_{l=1}^L p(z_l | f_l(z_{l+1}))\]</div><p>Here, each latent variable <span>$z_l$</span> (including <span>$z_{L+1}=z$</span>) has a unit Gaussian prior <span>$p(z_l) = \mathcal{N}(0, I)$</span>, and functions <span>$f_i$</span> are all parametrized by a deep neural network. We denote the set of weights and biases of all neural networks by <span>$\psi$</span>, and the statistical model for <span>$\theta$</span> is written as <span>$p_\psi(\theta|z)$</span>. Therefore, we have</p><div>\[\begin{aligned}
p_\psi( y|z) &amp;= p( y|\theta, z)p_\psi(\theta|z)\\ 
&amp;= p( y|\theta)p_\psi(\theta|z)\\ 
&amp;\propto  \exp\left[ -\frac{1}{2\sigma^2} ( y-y(\theta))^T( y-y(\theta)) \right] p_\psi(\theta|z)
\end{aligned}\]</div><p>Next, we approximate the posterior distribution by <span>$p_\phi(z|\tilde y) \approx p(z|\tilde y)$</span>, where <span>$p_\phi$</span> is a normalizing flow-based generative model, whose explaination is delayed to a later text. The negative standard evidence lower bound (ELBO) is derived as  <span>$L(y) = KL(p_\phi(z|y)|| p(z)) - \mathbb{E}_{p_\psi(y|z)} \log p(y|z) \geq -\log p_{\phi, \psi}(y)$</span> To find a good local minima for <span>$\phi$</span> and <span>$\psi$</span>, we minimize the ELBO using stochastic gradient descent method. The biggest challengee is how to compute <span>$\nabla_\psi \mathbb{E}_{p_\psi(y|z)} \log p(y|z)$</span>. We apply the stochastic backpropagation method, which relies on a Monte Carlo approximation of the gradient using  <span>$XXX$</span> </p><p>Once <span>$\phi$</span> and <span>$\psi$</span> are estimated, we can reconstruct the posterior distribution of <span>$p(\theta|y)$</span> using </p><div>\[p(\theta|y) = \int p(\theta|z, y)p(z) dz \approx \int p_{\phi}(\theta|z) p(z) dz\]</div><p>Because we can sample from the posterior distribution <span>$p_\psi(\theta|y)$</span> cheaply, we can generate samples from the data distribution relatively faster than MCMC. </p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Methods such as kernel density estimation (KDE) can reconstruct density functions out of samples. However, those methods face challenges in high dimensions or require voluminous samples, which can be expensive to generate. </li></ul></section></article></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 1 May 2020 09:33">Friday 1 May 2020</span>. Using Julia version 1.4.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
